{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# CPU Financial Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1760699519028,
     "user": {
      "displayName": "Lilian Aveneau",
      "userId": "13487831906381711345"
     },
     "user_tz": -420
    },
    "id": "universal_setup",
    "outputId": "615a983a-148f-4ccc-b750-c6cb4e20cfe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU NOTEBOOK WITH SEGMENTED REDUCE LOADED\n",
      "Environment detected: jupyter\n",
      "Current directory: /home/quydx/advancedhpc2025/project\n",
      "Ready to implement and test SCAN + REDUCE operations!\n"
     ]
    }
   ],
   "source": [
    "# Universal environment detection and setup\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import unittest\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def detect_environment():\n",
    "    \"\"\"Detect if we're running in Colab, local Jupyter, or other environment.\"\"\"\n",
    "    try:\n",
    "        import google.colab\n",
    "        return 'colab'\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if get_ipython() is not None:\n",
    "            if 'ipykernel' in str(get_ipython()):\n",
    "                return 'jupyter'\n",
    "        return 'local'\n",
    "    except:\n",
    "        return 'local'\n",
    "\n",
    "CURRENT_ENV = detect_environment()\n",
    "print(f\"CPU NOTEBOOK WITH SEGMENTED REDUCE LOADED\")\n",
    "print(f\"Environment detected: {CURRENT_ENV}\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Ready to implement and test SCAN + REDUCE operations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpu_implementations"
   },
   "source": [
    "## CPU Implementations - SCAN + REDUCE Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1760699519136,
     "user": {
      "displayName": "Lilian Aveneau",
      "userId": "13487831906381711345"
     },
     "user_tz": -420
    },
    "id": "cpu_primitives_complete",
    "outputId": "0ff8b074-6420-46e1-8561-41e9c4a2b2eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions available:\n",
      "   • SCAN: exclusive_scan, segmented_scan_sum, segmented_scan_max\n",
      "   • REDUCE: segmented_reduce_sum, segmented_reduce_max, segmented_reduce_min\n"
     ]
    }
   ],
   "source": [
    "class CPUFinancialPrimitives:\n",
    "    \"\"\" CPU primitive implementations - SCAN + REDUCE.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_input(data, expected_dtype=None, min_length=0):\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            raise TypeError(f\"Expected numpy array, got {type(data)}\")\n",
    "        if len(data) < min_length:\n",
    "            raise ValueError(f\"Array too short: {len(data)} < {min_length}\")\n",
    "        if expected_dtype and len(data) > 0 and data.dtype != expected_dtype:\n",
    "            raise ValueError(f\"Expected dtype {expected_dtype}, got {data.dtype}\")\n",
    "\n",
    "    # =============================================\n",
    "    # EXCLUSIVE SCAN\n",
    "    # =============================================\n",
    "    @staticmethod\n",
    "    def exclusive_scan(flags):\n",
    "        \"\"\" Convert segment boundary flags to segment IDs.\"\"\"\n",
    "        CPUFinancialPrimitives.validate_input(flags, np.int32)\n",
    "        if len(flags) == 0:\n",
    "            return np.array([], dtype=np.int32)\n",
    "\n",
    "        result = np.zeros_like(flags, dtype=np.int32)\n",
    "        for i in range(len(flags)):\n",
    "            if i == 0:\n",
    "                result[i] = 0\n",
    "            else:\n",
    "                result[i] = result[i-1] + flags[i-1]\n",
    "        return result\n",
    "2\n",
    "    # =============================================\n",
    "    # SEGMENTED SCAN OPERATIONS\n",
    "    # =============================================\n",
    "    @staticmethod\n",
    "    def segmented_scan_sum(values, seg_ids):\n",
    "        \"\"\" Segmented scan sum - cumulative sum within segments.\"\"\"\n",
    "        CPUFinancialPrimitives.validate_input(values, np.float32)\n",
    "        CPUFinancialPrimitives.validate_input(seg_ids, np.int32)\n",
    "\n",
    "        if len(values) != len(seg_ids):\n",
    "            raise ValueError(f\"Length mismatch: values {len(values)} vs seg_ids {len(seg_ids)}\")\n",
    "        if len(values) == 0:\n",
    "            return np.array([], dtype=np.float32)\n",
    "\n",
    "        result = np.zeros_like(values, dtype=np.float32)\n",
    "        current_sum = values[0]\n",
    "        result[0] = current_sum\n",
    "        current_seg = seg_ids[0]\n",
    "\n",
    "        for i in range(1, len(values)):\n",
    "            if seg_ids[i] != current_seg:\n",
    "                current_sum = values[i]  # Reset for new segment\n",
    "                current_seg = seg_ids[i]\n",
    "            else:\n",
    "                current_sum += values[i]  # Accumulate in same segment\n",
    "            result[i] = current_sum\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def segmented_scan_max(values, seg_ids):\n",
    "        \"\"\" Segmented scan max - cumulative max within segments.\"\"\"\n",
    "        CPUFinancialPrimitives.validate_input(values, np.float32)\n",
    "        CPUFinancialPrimitives.validate_input(seg_ids, np.int32)\n",
    "\n",
    "        if len(values) != len(seg_ids):\n",
    "            raise ValueError(f\"Length mismatch: values {len(values)} vs seg_ids {len(seg_ids)}\")\n",
    "        if len(values) == 0:\n",
    "            return np.array([], dtype=np.float32)\n",
    "\n",
    "        result = np.zeros_like(values, dtype=np.float32)\n",
    "        current_max = values[0]\n",
    "        result[0] = current_max\n",
    "        current_seg = seg_ids[0]\n",
    "\n",
    "        for i in range(1, len(values)):\n",
    "            if seg_ids[i] != current_seg:\n",
    "                current_max = values[i]  # Reset for new segment\n",
    "                current_seg = seg_ids[i]\n",
    "            else:\n",
    "                current_max = max(current_max, values[i])\n",
    "            result[i] = current_max\n",
    "        return result\n",
    "\n",
    "    # =============================================\n",
    "    # SEGMENTED REDUCE OPERATIONS\n",
    "    # =============================================\n",
    "    @staticmethod\n",
    "    def segmented_reduce_sum(values, seg_ids):\n",
    "        \"\"\" Segmented reduce sum - final sum per segment.\n",
    "\n",
    "        Returns one result per unique segment (not cumulative).\n",
    "\n",
    "        Example:\n",
    "            values = [5, 3, 2, 7, 1, 4, 6, 8]\n",
    "            seg_ids = [0, 0, 0, 1, 1, 2, 2, 2]\n",
    "            result = [10, 8, 18]  # [5+3+2, 7+1, 4+6+8]\n",
    "        \"\"\"\n",
    "        CPUFinancialPrimitives.validate_input(values, np.float32)\n",
    "        CPUFinancialPrimitives.validate_input(seg_ids, np.int32)\n",
    "\n",
    "        if len(values) != len(seg_ids):\n",
    "            raise ValueError(f\"Length mismatch: values {len(values)} vs seg_ids {len(seg_ids)}\")\n",
    "        if len(values) == 0:\n",
    "            return np.array([], dtype=np.float32)\n",
    "\n",
    "        segment_sums = {}\n",
    "        segment_order = []\n",
    "\n",
    "        for i in range(len(values)):\n",
    "            seg_id = seg_ids[i]\n",
    "            if seg_id not in segment_sums:\n",
    "                segment_order.append(seg_id)\n",
    "                segment_sums[seg_id] = 0.0\n",
    "            segment_sums[seg_id] += values[i]\n",
    "\n",
    "        # Convert to array in order\n",
    "        result = np.array([segment_sums[seg_id] for seg_id in segment_order], dtype=np.float32)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def segmented_reduce_max(values, seg_ids):\n",
    "        \"\"\" Segmented reduce max - maximum value per segment.\n",
    "\n",
    "        Returns one result per unique segment.\n",
    "\n",
    "        Example:\n",
    "            values = [5, 3, 2, 7, 1, 4, 6, 8]\n",
    "            seg_ids = [0, 0, 0, 1, 1, 2, 2, 2]\n",
    "            result = [5, 7, 8]  # [max(5,3,2), max(7,1), max(4,6,8)]\n",
    "        \"\"\"\n",
    "        CPUFinancialPrimitives.validate_input(values, np.float32)\n",
    "        CPUFinancialPrimitives.validate_input(seg_ids, np.int32)\n",
    "\n",
    "        if len(values) != len(seg_ids):\n",
    "            raise ValueError(f\"Length mismatch: values {len(values)} vs seg_ids {len(seg_ids)}\")\n",
    "        if len(values) == 0:\n",
    "            return np.array([], dtype=np.float32)\n",
    "\n",
    "        segment_max = {}\n",
    "        segment_order = []\n",
    "\n",
    "        for i in range(len(values)):\n",
    "            seg_id = seg_ids[i]\n",
    "            if seg_id not in segment_max:\n",
    "                segment_order.append(seg_id)\n",
    "                segment_max[seg_id] = values[i]\n",
    "            else:\n",
    "                segment_max[seg_id] = max(segment_max[seg_id], values[i])\n",
    "\n",
    "        # Convert to array in order\n",
    "        result = np.array([segment_max[seg_id] for seg_id in segment_order], dtype=np.float32)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def segmented_reduce_min(values, seg_ids):\n",
    "        \"\"\" Segmented reduce min - minimum value per segment.\n",
    "\n",
    "        Returns one result per unique segment.\n",
    "\n",
    "        Example:\n",
    "            values = [5, 3, 2, 7, 1, 4, 6, 8]\n",
    "            seg_ids = [0, 0, 0, 1, 1, 2, 2, 2]\n",
    "            result = [2, 1, 4]  # [min(5,3,2), min(7,1), min(4,6,8)]\n",
    "        \"\"\"\n",
    "        CPUFinancialPrimitives.validate_input(values, np.float32)\n",
    "        CPUFinancialPrimitives.validate_input(seg_ids, np.int32)\n",
    "\n",
    "        if len(values) != len(seg_ids):\n",
    "            raise ValueError(f\"Length mismatch: values {len(values)} vs seg_ids {len(seg_ids)}\")\n",
    "        if len(values) == 0:\n",
    "            return np.array([], dtype=np.float32)\n",
    "\n",
    "        segment_min = {}\n",
    "        segment_order = []\n",
    "\n",
    "        for i in range(len(values)):\n",
    "            seg_id = seg_ids[i]\n",
    "            if seg_id not in segment_min:\n",
    "                segment_order.append(seg_id)\n",
    "                segment_min[seg_id] = values[i]\n",
    "            else:\n",
    "                segment_min[seg_id] = min(segment_min[seg_id], values[i])\n",
    "\n",
    "        # Convert to array in order\n",
    "        result = np.array([segment_min[seg_id] for seg_id in segment_order], dtype=np.float32)\n",
    "        return result\n",
    "\n",
    "print(\"Functions available:\")\n",
    "print(\"   • SCAN: exclusive_scan, segmented_scan_sum, segmented_scan_max\")\n",
    "print(\"   • REDUCE: segmented_reduce_sum, segmented_reduce_max, segmented_reduce_min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpu_financial_metrics"
   },
   "source": [
    "## Financial Metrics (Using Primitives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1760699519348,
     "user": {
      "displayName": "Lilian Aveneau",
      "userId": "13487831906381711345"
     },
     "user_tz": -420
    },
    "id": "cpu_financial_implementations"
   },
   "outputs": [],
   "source": [
    "class CPUFinancialMetrics:\n",
    "    \"\"\" CPU financial metric implementations using scan/reduce primitives.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def cumulative_returns(prices, seg_ids):\n",
    "        \"\"\" Cumulative returns calculation using segmented_scan_sum.\"\"\"\n",
    "        if len(prices) <= 1:\n",
    "            return np.zeros_like(prices, dtype=np.float32)\n",
    "\n",
    "        CPUFinancialPrimitives.validate_input(prices, np.float32)\n",
    "        CPUFinancialPrimitives.validate_input(seg_ids, np.int32)\n",
    "\n",
    "        # Calculate daily returns\n",
    "        returns = np.zeros_like(prices, dtype=np.float32)\n",
    "        for i in range(1, len(prices)):\n",
    "            if seg_ids[i] != seg_ids[i-1]:\n",
    "                returns[i] = 0.0  # Reset at segment boundary\n",
    "            elif prices[i-1] > 0:\n",
    "                returns[i] = prices[i] / prices[i-1] - 1.0\n",
    "            else:\n",
    "                returns[i] = 0.0\n",
    "\n",
    "        # Convert to log returns and apply segmented scan\n",
    "        log_returns = np.log(1.0 + np.clip(returns, -0.999, 10.0))\n",
    "        cum_log_returns = CPUFinancialPrimitives.segmented_scan_sum(log_returns, seg_ids)\n",
    "        return np.exp(cum_log_returns) - 1.0\n",
    "\n",
    "    @staticmethod\n",
    "    def simple_moving_average(prices, seg_ids, window=5):\n",
    "        \"\"\"Simple moving average - OPTIMIZED version.\"\"\"\n",
    "        CPUFinancialPrimitives.validate_input(prices, np.float32)\n",
    "        CPUFinancialPrimitives.validate_input(seg_ids, np.int32)\n",
    "\n",
    "        if window <= 0:\n",
    "            raise ValueError(f\"Window must be positive, got {window}\")\n",
    "        if len(prices) == 0:\n",
    "            return np.array([], dtype=np.float32)\n",
    "\n",
    "        result = np.zeros_like(prices, dtype=np.float32)\n",
    "\n",
    "        # Precompute segment boundaries - single pass O(n)\n",
    "        segment_starts = np.zeros(len(prices), dtype=np.int32)\n",
    "        current_seg = seg_ids[0]\n",
    "        current_start = 0\n",
    "\n",
    "        for i in range(len(prices)):\n",
    "            if seg_ids[i] != current_seg:\n",
    "                current_seg = seg_ids[i]\n",
    "                current_start = i\n",
    "            segment_starts[i] = current_start\n",
    "\n",
    "        # Calculate moving averages - O(n×w) where w=window\n",
    "        for i in range(len(prices)):\n",
    "            seg_start = segment_starts[i]\n",
    "            window_start = max(seg_start, i - window + 1)\n",
    "\n",
    "            # Calculate sum of valid (non-zero) prices in window\n",
    "            count = 0\n",
    "            total = 0.0\n",
    "            for j in range(window_start, i + 1):\n",
    "                if prices[j] > 0:\n",
    "                    total += prices[j]\n",
    "                    count += 1\n",
    "\n",
    "            if count > 0:\n",
    "                result[i] = total / count\n",
    "            elif prices[i] > 0:\n",
    "                result[i] = prices[i]\n",
    "            else:\n",
    "                result[i] = 0.0\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def rolling_std(prices, seg_ids, window=20):\n",
    "        \"\"\"Rolling standard deviation - OPTIMIZED version.\"\"\"\n",
    "        CPUFinancialPrimitives.validate_input(prices, np.float32)\n",
    "        CPUFinancialPrimitives.validate_input(seg_ids, np.int32)\n",
    "\n",
    "        if window <= 1:\n",
    "            raise ValueError(f\"Window must be > 1 for std calculation, got {window}\")\n",
    "        if len(prices) == 0:\n",
    "            return np.array([], dtype=np.float32)\n",
    "\n",
    "        result = np.zeros_like(prices, dtype=np.float32)\n",
    "\n",
    "        # Precompute segment boundaries - single pass O(n)\n",
    "        segment_starts = np.zeros(len(prices), dtype=np.int32)\n",
    "        current_seg = seg_ids[0]\n",
    "        current_start = 0\n",
    "\n",
    "        for i in range(len(prices)):\n",
    "            if seg_ids[i] != current_seg:\n",
    "                current_seg = seg_ids[i]\n",
    "                current_start = i\n",
    "            segment_starts[i] = current_start\n",
    "\n",
    "        # Calculate rolling std - O(n×w)\n",
    "        for i in range(len(prices)):\n",
    "            seg_start = segment_starts[i]\n",
    "            window_start = max(seg_start, i - window + 1)\n",
    "\n",
    "            # Collect valid prices in window\n",
    "            valid_prices = []\n",
    "            for j in range(window_start, i + 1):\n",
    "                if prices[j] > 0:\n",
    "                    valid_prices.append(prices[j])\n",
    "\n",
    "            if len(valid_prices) > 1:\n",
    "                # Calculate std using two-pass algorithm for numerical stability\n",
    "                mean = sum(valid_prices) / len(valid_prices)\n",
    "                variance = sum((x - mean) ** 2 for x in valid_prices) / (len(valid_prices) - 1)\n",
    "                result[i] = np.sqrt(variance)\n",
    "            else:\n",
    "                result[i] = 0.0\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def max_drawdown(prices, seg_ids):\n",
    "        \"\"\" Maximum drawdown using segmented_scan_max.\"\"\"\n",
    "        running_max = CPUFinancialPrimitives.segmented_scan_max(prices, seg_ids)\n",
    "        return prices - running_max\n",
    "\n",
    "    @staticmethod\n",
    "    def portfolio_value(holdings, prices):\n",
    "        \"\"\" Portfolio value calculation.\"\"\"\n",
    "        if holdings.shape != prices.shape:\n",
    "            raise ValueError(f\"Shape mismatch: holdings {holdings.shape} vs prices {prices.shape}\")\n",
    "        return np.sum(holdings * prices, axis=0).astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def high_water_mark(portfolio_values, seg_ids):\n",
    "        \"\"\" High-water mark using segmented_scan_max.\"\"\"\n",
    "        return CPUFinancialPrimitives.segmented_scan_max(portfolio_values, seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unittest_tests"
   },
   "source": [
    "## Comprehensive Unit Tests - SCAN + REDUCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1760699519442,
     "user": {
      "displayName": "Lilian Aveneau",
      "userId": "13487831906381711345"
     },
     "user_tz": -420
    },
    "id": "test_primitives_complete"
   },
   "outputs": [],
   "source": [
    "class TestCPUPrimitivesComplete(unittest.TestCase):\n",
    "    \"\"\"Comprehensive tests for ALL CPU primitives - SCAN + REDUCE.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        self.test_flags = np.array([0, 0, 1, 0, 1, 0, 0, 1], dtype=np.int32)  # Corrected: flags at END\n",
    "        self.test_values = np.array([5.0, 3.0, 2.0, 7.0, 1.0, 4.0, 6.0, 8.0], dtype=np.float32)\n",
    "        self.expected_seg_ids = np.array([0, 0, 0, 1, 1, 2, 2, 2], dtype=np.int32)\n",
    "        self.tolerance = 1e-6\n",
    "\n",
    "    # ===== SCAN TESTS =====\n",
    "    def test_exclusive_scan_correctness(self):\n",
    "        \"\"\" Test exclusive scan produces correct segment IDs.\"\"\"\n",
    "        result = CPUFinancialPrimitives.exclusive_scan(self.test_flags)\n",
    "        np.testing.assert_array_equal(result, self.expected_seg_ids)\n",
    "\n",
    "    def test_segmented_scan_sum_correctness(self):\n",
    "        \"\"\" Test segmented scan sum produces correct cumulative results.\"\"\"\n",
    "        expected = np.array([5.0, 8.0, 10.0, 7.0, 8.0, 4.0, 10.0, 18.0], dtype=np.float32)\n",
    "        result = CPUFinancialPrimitives.segmented_scan_sum(self.test_values, self.expected_seg_ids)\n",
    "        np.testing.assert_allclose(result, expected, rtol=self.tolerance)\n",
    "\n",
    "    def test_segmented_scan_max_correctness(self):\n",
    "        \"\"\" Test segmented scan max produces correct cumulative max.\"\"\"\n",
    "        expected = np.array([5.0, 5.0, 5.0, 7.0, 7.0, 4.0, 6.0, 8.0], dtype=np.float32)\n",
    "        result = CPUFinancialPrimitives.segmented_scan_max(self.test_values, self.expected_seg_ids)\n",
    "        np.testing.assert_allclose(result, expected, rtol=self.tolerance)\n",
    "\n",
    "    # ===== REDUCE TESTS =====\n",
    "    def test_segmented_reduce_sum_correctness(self):\n",
    "        \"\"\" Test segmented reduce sum produces correct final sums.\"\"\"\n",
    "        # Expected: [5+3+2, 7+1, 4+6+8] = [10, 8, 18]\n",
    "        expected = np.array([10.0, 8.0, 18.0], dtype=np.float32)\n",
    "        result = CPUFinancialPrimitives.segmented_reduce_sum(self.test_values, self.expected_seg_ids)\n",
    "\n",
    "        self.assertEqual(len(result), 3, \"Should have 3 segments\")\n",
    "        np.testing.assert_allclose(result, expected, rtol=self.tolerance,\n",
    "            err_msg=\"Reduce sum should compute final sum per segment\")\n",
    "\n",
    "    def test_segmented_reduce_max_correctness(self):\n",
    "        \"\"\" Test segmented reduce max produces correct max per segment.\"\"\"\n",
    "        # Expected: [max(5,3,2), max(7,1), max(4,6,8)] = [5, 7, 8]\n",
    "        expected = np.array([5.0, 7.0, 8.0], dtype=np.float32)\n",
    "        result = CPUFinancialPrimitives.segmented_reduce_max(self.test_values, self.expected_seg_ids)\n",
    "\n",
    "        self.assertEqual(len(result), 3, \"Should have 3 segments\")\n",
    "        np.testing.assert_allclose(result, expected, rtol=self.tolerance,\n",
    "            err_msg=\"Reduce max should compute max value per segment\")\n",
    "\n",
    "    def test_segmented_reduce_min_correctness(self):\n",
    "        \"\"\" Test segmented reduce min produces correct min per segment.\"\"\"\n",
    "        # Expected: [min(5,3,2), min(7,1), min(4,6,8)] = [2, 1, 4]\n",
    "        expected = np.array([2.0, 1.0, 4.0], dtype=np.float32)\n",
    "        result = CPUFinancialPrimitives.segmented_reduce_min(self.test_values, self.expected_seg_ids)\n",
    "\n",
    "        self.assertEqual(len(result), 3, \"Should have 3 segments\")\n",
    "        np.testing.assert_allclose(result, expected, rtol=self.tolerance,\n",
    "            err_msg=\"Reduce min should compute min value per segment\")\n",
    "\n",
    "    def test_reduce_edge_cases(self):\n",
    "        \"\"\" Test reduce operations with edge cases.\"\"\"\n",
    "        # Empty arrays\n",
    "        empty_values = np.array([], dtype=np.float32)\n",
    "        empty_seg_ids = np.array([], dtype=np.int32)\n",
    "\n",
    "        sum_result = CPUFinancialPrimitives.segmented_reduce_sum(empty_values, empty_seg_ids)\n",
    "        max_result = CPUFinancialPrimitives.segmented_reduce_max(empty_values, empty_seg_ids)\n",
    "        min_result = CPUFinancialPrimitives.segmented_reduce_min(empty_values, empty_seg_ids)\n",
    "\n",
    "        self.assertEqual(len(sum_result), 0)\n",
    "        self.assertEqual(len(max_result), 0)\n",
    "        self.assertEqual(len(min_result), 0)\n",
    "\n",
    "        # Single element\n",
    "        single_values = np.array([42.0], dtype=np.float32)\n",
    "        single_seg_ids = np.array([0], dtype=np.int32)\n",
    "\n",
    "        sum_single = CPUFinancialPrimitives.segmented_reduce_sum(single_values, single_seg_ids)\n",
    "        max_single = CPUFinancialPrimitives.segmented_reduce_max(single_values, single_seg_ids)\n",
    "        min_single = CPUFinancialPrimitives.segmented_reduce_min(single_values, single_seg_ids)\n",
    "\n",
    "        np.testing.assert_allclose(sum_single, [42.0])\n",
    "        np.testing.assert_allclose(max_single, [42.0])\n",
    "        np.testing.assert_allclose(min_single, [42.0])\n",
    "\n",
    "    def test_scan_vs_reduce_consistency(self):\n",
    "        \"\"\" Test that scan and reduce operations are consistent.\"\"\"\n",
    "        # The last value in each segment's scan should equal the reduce result\n",
    "        scan_sum = CPUFinancialPrimitives.segmented_scan_sum(self.test_values, self.expected_seg_ids)\n",
    "        reduce_sum = CPUFinancialPrimitives.segmented_reduce_sum(self.test_values, self.expected_seg_ids)\n",
    "\n",
    "        scan_max = CPUFinancialPrimitives.segmented_scan_max(self.test_values, self.expected_seg_ids)\n",
    "        reduce_max = CPUFinancialPrimitives.segmented_reduce_max(self.test_values, self.expected_seg_ids)\n",
    "\n",
    "        # Extract last value of each segment from scan\n",
    "        segment_ends = [2, 4, 7]  # Indices where segments end\n",
    "        scan_sum_finals = scan_sum[segment_ends]\n",
    "        scan_max_finals = scan_max[segment_ends]\n",
    "\n",
    "        np.testing.assert_allclose(scan_sum_finals, reduce_sum, rtol=self.tolerance,\n",
    "            err_msg=\"Final scan values should match reduce results for sum\")\n",
    "        np.testing.assert_allclose(scan_max_finals, reduce_max, rtol=self.tolerance,\n",
    "            err_msg=\"Final scan values should match reduce results for max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1760699519517,
     "user": {
      "displayName": "Lilian Aveneau",
      "userId": "13487831906381711345"
     },
     "user_tz": -420
    },
    "id": "test_financial_metrics"
   },
   "outputs": [],
   "source": [
    "class TestCPUFinancialMetrics(unittest.TestCase):\n",
    "    \"\"\" Comprehensive tests for financial metrics (unchanged).\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        self.tolerance = 1e-5\n",
    "\n",
    "        # Test data\n",
    "        self.prices = np.array([100.0, 102.0, 101.0, 105.0, 103.0,\n",
    "                               110.0, 108.0, 112.0, 115.0, 113.0], dtype=np.float32)\n",
    "        self.seg_ids = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype=np.int32)\n",
    "\n",
    "        # Portfolio data\n",
    "        self.n_securities = 2\n",
    "        self.n_days = len(self.prices)\n",
    "        self.prices_multi = np.array([[100.0, 102.0, 101.0, 105.0, 103.0, 110.0, 108.0, 112.0, 115.0, 113.0],\n",
    "                                     [50.0, 51.0, 50.5, 52.5, 51.5, 55.0, 54.0, 56.0, 57.5, 56.5]], dtype=np.float32)\n",
    "        self.holdings = np.array([[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0],\n",
    "                                 [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]], dtype=np.float32)\n",
    "\n",
    "    def test_cumulative_returns_mathematical_correctness(self):\n",
    "        \"\"\"Test cumulative returns calculation.\"\"\"\n",
    "        result = CPUFinancialMetrics.cumulative_returns(self.prices, self.seg_ids)\n",
    "\n",
    "        self.assertEqual(len(result), len(self.prices))\n",
    "        self.assertAlmostEqual(result[0], 0.0, places=6)\n",
    "        self.assertAlmostEqual(result[5], 0.0, places=6)  # Segment boundary reset\n",
    "        self.assertFalse(np.any(np.isnan(result)))\n",
    "\n",
    "    def test_simple_moving_average_mathematical_correctness(self):\n",
    "        \"\"\"Test SMA calculation.\"\"\"\n",
    "        window = 3\n",
    "        result = CPUFinancialMetrics.simple_moving_average(self.prices, self.seg_ids, window)\n",
    "\n",
    "        self.assertEqual(len(result), len(self.prices))\n",
    "        self.assertAlmostEqual(result[0], 100.0, places=3)\n",
    "        self.assertAlmostEqual(result[1], 101.0, places=3)\n",
    "        self.assertTrue(np.all(result > 0))\n",
    "\n",
    "    def test_rolling_std_mathematical_correctness(self):\n",
    "        \"\"\"Test rolling standard deviation.\"\"\"\n",
    "        window = 3\n",
    "        result = CPUFinancialMetrics.rolling_std(self.prices, self.seg_ids, window)\n",
    "\n",
    "        self.assertTrue(np.all(result >= 0))\n",
    "        self.assertGreaterEqual(result[0], 0)\n",
    "\n",
    "    def test_max_drawdown_mathematical_correctness(self):\n",
    "        \"\"\"Test max drawdown calculation.\"\"\"\n",
    "        result = CPUFinancialMetrics.max_drawdown(self.prices, self.seg_ids)\n",
    "\n",
    "        self.assertTrue(np.all(result <= 0.001))  # Should be <= 0\n",
    "        self.assertEqual(len(result), len(self.prices))\n",
    "        self.assertAlmostEqual(result[2], -1.0, places=3)  # 101 - 102 = -1\n",
    "\n",
    "    def test_portfolio_value_mathematical_correctness(self):\n",
    "        \"\"\"Test portfolio value calculation.\"\"\"\n",
    "        result = CPUFinancialMetrics.portfolio_value(self.holdings, self.prices_multi)\n",
    "\n",
    "        expected_day_0 = 100*100 + 200*50  # 20000\n",
    "        self.assertAlmostEqual(result[0], expected_day_0, places=1)\n",
    "\n",
    "        self.assertEqual(len(result), self.n_days)\n",
    "        self.assertTrue(np.all(result > 0))\n",
    "\n",
    "    def test_high_water_mark_mathematical_correctness(self):\n",
    "        \"\"\"Test high-water mark calculation.\"\"\"\n",
    "        portfolio_values = CPUFinancialMetrics.portfolio_value(self.holdings, self.prices_multi)\n",
    "        result = CPUFinancialMetrics.high_water_mark(portfolio_values, self.seg_ids)\n",
    "\n",
    "        # HWM should be non-decreasing within segments\n",
    "        for seg_id in np.unique(self.seg_ids):\n",
    "            seg_mask = self.seg_ids == seg_id\n",
    "            seg_hwm = result[seg_mask]\n",
    "\n",
    "            for i in range(1, len(seg_hwm)):\n",
    "                self.assertGreaterEqual(seg_hwm[i], seg_hwm[i-1] - 1e-6)\n",
    "\n",
    "        self.assertEqual(len(result), len(portfolio_values))\n",
    "        self.assertTrue(np.all(result > 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_tests"
   },
   "source": [
    "## Run Test Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1760699519764,
     "user": {
      "displayName": "Lilian Aveneau",
      "userId": "13487831906381711345"
     },
     "user_tz": -420
    },
    "id": "run_comprehensive_tests",
    "outputId": "838f2227-5fbd-4140-d56d-c202f39a37e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_exclusive_scan_correctness (__main__.TestCPUPrimitivesComplete.test_exclusive_scan_correctness)\n",
      "Test exclusive scan produces correct segment IDs. ... ok\n",
      "test_reduce_edge_cases (__main__.TestCPUPrimitivesComplete.test_reduce_edge_cases)\n",
      "Test reduce operations with edge cases. ... ok\n",
      "test_scan_vs_reduce_consistency (__main__.TestCPUPrimitivesComplete.test_scan_vs_reduce_consistency)\n",
      "Test that scan and reduce operations are consistent. ... ok\n",
      "test_segmented_reduce_max_correctness (__main__.TestCPUPrimitivesComplete.test_segmented_reduce_max_correctness)\n",
      "Test segmented reduce max produces correct max per segment. ... ok\n",
      "test_segmented_reduce_min_correctness (__main__.TestCPUPrimitivesComplete.test_segmented_reduce_min_correctness)\n",
      "Test segmented reduce min produces correct min per segment. ... ok\n",
      "test_segmented_reduce_sum_correctness (__main__.TestCPUPrimitivesComplete.test_segmented_reduce_sum_correctness)\n",
      "Test segmented reduce sum produces correct final sums. ... ok\n",
      "test_segmented_scan_max_correctness (__main__.TestCPUPrimitivesComplete.test_segmented_scan_max_correctness)\n",
      "Test segmented scan max produces correct cumulative max. ... ok\n",
      "test_segmented_scan_sum_correctness (__main__.TestCPUPrimitivesComplete.test_segmented_scan_sum_correctness)\n",
      "Test segmented scan sum produces correct cumulative results. ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 8 tests in 0.009s\n",
      "\n",
      "OK\n",
      "test_cumulative_returns_mathematical_correctness (__main__.TestCPUFinancialMetrics.test_cumulative_returns_mathematical_correctness)\n",
      "Test cumulative returns calculation. ... ok\n",
      "test_high_water_mark_mathematical_correctness (__main__.TestCPUFinancialMetrics.test_high_water_mark_mathematical_correctness)\n",
      "Test high-water mark calculation. ... ok\n",
      "test_max_drawdown_mathematical_correctness (__main__.TestCPUFinancialMetrics.test_max_drawdown_mathematical_correctness)\n",
      "Test max drawdown calculation. ... ok\n",
      "test_portfolio_value_mathematical_correctness (__main__.TestCPUFinancialMetrics.test_portfolio_value_mathematical_correctness)\n",
      "Test portfolio value calculation. ... ok\n",
      "test_rolling_std_mathematical_correctness (__main__.TestCPUFinancialMetrics.test_rolling_std_mathematical_correctness)\n",
      "Test rolling standard deviation. ... ok\n",
      "test_simple_moving_average_mathematical_correctness (__main__.TestCPUFinancialMetrics.test_simple_moving_average_mathematical_correctness)\n",
      "Test SMA calculation. ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.012s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RUNNING COMPREHENSIVE TEST SUITE\n",
      "======================================================================\n",
      "\n",
      "==================== CPU Primitives (Scan + Reduce) ====================\n",
      "Running 8 test methods...\n",
      "\n",
      "CPU Primitives (Scan + Reduce) Results: 100.0% pass rate (8/8 tests)\n",
      "\n",
      "==================== CPU Financial Metrics ====================\n",
      "Running 6 test methods...\n",
      "\n",
      "CPU Financial Metrics Results: 100.0% pass rate (6/6 tests)\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE TEST SUMMARY - ALL PRIMITIVES + FINANCIAL METRICS\n",
      "======================================================================\n",
      "Test Statistics:\n",
      "   Total tests run: 14\n",
      "   Passed: 14\n",
      "   Failed: 0\n",
      "   Errors: 0\n",
      "   Overall success rate: 100.0%\n",
      "\n",
      "Functions Tested:\n",
      "   exclusive_scan - segment ID generation\n",
      "   segmented_scan_sum - cumulative sum within segments\n",
      "   segmented_scan_max - cumulative max within segments\n",
      "   segmented_reduce_sum - final sum per segment\n",
      "   segmented_reduce_max - max value per segment\n",
      "   segmented_reduce_min - min value per segment\n",
      "   cumulative_returns - portfolio return calculation\n",
      "   simple_moving_average - windowed averaging\n",
      "   rolling_std - rolling standard deviation\n",
      "   max_drawdown - maximum drawdown calculation\n",
      "   portfolio_value - multi-security valuation\n",
      "   high_water_mark - high-water mark tracking\n",
      "\n",
      "ALL TESTS PASSED! VALIDATION ACHIEVED!\n",
      "All 12/12 functions (6 primitives + 6 financial) are working correctly\n",
      "Segmented REDUCE operations successfully added!\n",
      "Ready to generate test fixtures\n",
      "\n",
      "SUCCESS: All CPU implementations are validated!\n"
     ]
    }
   ],
   "source": [
    "def run_comprehensive_test_suite_with_reduce():\n",
    "    \"\"\"Run ALL tests - primitives (scan+reduce) AND financial metrics.\"\"\"\n",
    "    print(f\" RUNNING COMPREHENSIVE TEST SUITE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Test classes to run\n",
    "    test_classes = [\n",
    "        (TestCPUPrimitivesComplete, \"CPU Primitives (Scan + Reduce)\"),\n",
    "        (TestCPUFinancialMetrics, \"CPU Financial Metrics\")\n",
    "    ]\n",
    "\n",
    "    all_results = []\n",
    "    total_tests = 0\n",
    "    total_failures = 0\n",
    "    total_errors = 0\n",
    "\n",
    "    for test_class, description in test_classes:\n",
    "        print(f\"\\n{'='*20} {description} {'='*20}\")\n",
    "\n",
    "        # Create test suite\n",
    "        suite = unittest.TestLoader().loadTestsFromTestCase(test_class)\n",
    "\n",
    "        # Count methods\n",
    "        test_methods = [method for method in dir(test_class) if method.startswith('test_')]\n",
    "        print(f\"Running {len(test_methods)} test methods...\")\n",
    "\n",
    "        # Run with detailed output\n",
    "        runner = unittest.TextTestRunner(verbosity=2)\n",
    "        result = runner.run(suite)\n",
    "\n",
    "        all_results.append(result)\n",
    "        total_tests += result.testsRun\n",
    "        total_failures += len(result.failures)\n",
    "        total_errors += len(result.errors)\n",
    "\n",
    "        # Show results\n",
    "        success_rate = ((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100) if result.testsRun > 0 else 0\n",
    "        print(f\"\\n{description} Results: {success_rate:.1f}% pass rate ({result.testsRun - len(result.failures) - len(result.errors)}/{result.testsRun} tests)\")\n",
    "\n",
    "        if result.failures:\n",
    "            print(f\"Failures: {len(result.failures)}\")\n",
    "        if result.errors:\n",
    "            print(f\"Errors: {len(result.errors)}\")\n",
    "\n",
    "    # Overall summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"COMPREHENSIVE TEST SUMMARY - ALL PRIMITIVES + FINANCIAL METRICS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    success_rate = ((total_tests - total_failures - total_errors) / total_tests * 100) if total_tests > 0 else 0\n",
    "\n",
    "    print(f\"Test Statistics:\")\n",
    "    print(f\"   Total tests run: {total_tests}\")\n",
    "    print(f\"   Passed: {total_tests - total_failures - total_errors}\")\n",
    "    print(f\"   Failed: {total_failures}\")\n",
    "    print(f\"   Errors: {total_errors}\")\n",
    "    print(f\"   Overall success rate: {success_rate:.1f}%\")\n",
    "\n",
    "    print(f\"\\nFunctions Tested:\")\n",
    "    print(f\"   exclusive_scan - segment ID generation\")\n",
    "    print(f\"   segmented_scan_sum - cumulative sum within segments\")\n",
    "    print(f\"   segmented_scan_max - cumulative max within segments\")\n",
    "    print(f\"   segmented_reduce_sum - final sum per segment\")\n",
    "    print(f\"   segmented_reduce_max - max value per segment\")\n",
    "    print(f\"   segmented_reduce_min - min value per segment\")\n",
    "    print(f\"   cumulative_returns - portfolio return calculation\")\n",
    "    print(f\"   simple_moving_average - windowed averaging\")\n",
    "    print(f\"   rolling_std - rolling standard deviation\")\n",
    "    print(f\"   max_drawdown - maximum drawdown calculation\")\n",
    "    print(f\"   portfolio_value - multi-security valuation\")\n",
    "    print(f\"   high_water_mark - high-water mark tracking\")\n",
    "\n",
    "    if total_failures == 0 and total_errors == 0:\n",
    "        print(f\"\\nALL TESTS PASSED! VALIDATION ACHIEVED!\")\n",
    "        print(f\"All 12/12 functions (6 primitives + 6 financial) are working correctly\")\n",
    "        print(f\"Segmented REDUCE operations successfully added!\")\n",
    "        print(f\"Ready to generate test fixtures\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\\nSome tests failed - fix implementations before generating fixtures\")\n",
    "        return False\n",
    "\n",
    "# Run the comprehensive test suite\n",
    "all_tests_passed = run_comprehensive_test_suite_with_reduce()\n",
    "\n",
    "if all_tests_passed:\n",
    "    print(f\"\\nSUCCESS: All CPU implementations are validated!\")\n",
    "else:\n",
    "    print(f\"\\nFix any failing tests before proceeding to fixture generation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generate_fixtures"
   },
   "source": [
    "## Generate Test Fixtures with REDUCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5839,
     "status": "ok",
     "timestamp": 1760700041043,
     "user": {
      "displayName": "Lilian Aveneau",
      "userId": "13487831906381711345"
     },
     "user_tz": -420
    },
    "id": "generate_fixtures_with_reduce",
    "outputId": "cef0160b-58ed-4968-f287-b372fa585610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING TEST FIXTURES\n",
      "============================================================\n",
      "Computing ALL primitive operations...\n",
      "Computing all scan operations...\n",
      "Computing all reduce operations...\n",
      "Computing all financial metrics...\n",
      "SAVING FIXTURES cpu_test_fixtures_20251025_0904.json\n",
      "============================================================\n",
      "Saved locally: /home/quydx/advancedhpc2025/project/cpu_test_fixtures_20251025_0904.json\n",
      "SAVING FIXTURES cpu_test_fixtures.json\n",
      "============================================================\n",
      "Saved locally: /home/quydx/advancedhpc2025/project/cpu_test_fixtures.json\n",
      "\n",
      "TEST FIXTURES GENERATED!\n",
      "============================================================\n",
      "Timestamped: cpu_test_fixtures_20251025_0904.json\n",
      "Generic: gpu_test_fixtures.json\n",
      "\n",
      "VALIDATION SUMMARY:\n",
      "   Scan primitives (3/3): exclusive_scan, segmented_scan_sum, segmented_scan_max\n",
      "   Reduce primitives (3/3): segmented_reduce_sum, segmented_reduce_max, segmented_reduce_min\n",
      "   Financial metrics (6/6): ALL VALIDATED\n",
      "   Total functions: 12/12\n",
      "   Consistency checks: scan vs reduce verified\n",
      "\n",
      "SUCCESS! Complete test fixture!\n",
      "Students now have the full primitive toolkit for GPU implementation!\n"
     ]
    }
   ],
   "source": [
    "def save_fixtures_universal(test_suite, filename='cpu_test_fixtures.json'):\n",
    "    \"\"\"Universal fixture saving.\"\"\"\n",
    "    env = CURRENT_ENV\n",
    "    print(f\"SAVING FIXTURES {filename}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    if env == 'colab':\n",
    "        try:\n",
    "            from google.colab import drive, files\n",
    "            try:\n",
    "                drive.mount('/content/drive')\n",
    "                class_folder = \"/content/drive/MyDrive/HPC_Project_2025/Test_Fixtures\"\n",
    "                os.makedirs(class_folder, exist_ok=True)\n",
    "\n",
    "                drive_path = f\"{class_folder}/{filename}\"\n",
    "                with open(drive_path, 'w') as f:\n",
    "                    json.dump(test_suite, f, indent=2)\n",
    "\n",
    "                print(f\"Saved to Google Drive: {drive_path}\")\n",
    "                return drive_path\n",
    "            except Exception:\n",
    "                with open(filename, 'w') as f:\n",
    "                    json.dump(test_suite, f, indent=2)\n",
    "                files.download(filename)\n",
    "                return filename\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Local save\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(test_suite, f, indent=2)\n",
    "\n",
    "    full_path = f\"{os.getcwd()}/{filename}\"\n",
    "    print(f\"Saved locally: {full_path}\")\n",
    "    return full_path\n",
    "\n",
    "def generate_complete_fixtures():\n",
    "    \"\"\"Generate test fixtures.\"\"\"\n",
    "\n",
    "    if not all_tests_passed:\n",
    "        print(\"Cannot generate fixtures - all tests must pass first\")\n",
    "        return None\n",
    "\n",
    "    print(f\"GENERATING TEST FIXTURES\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Simple test data\n",
    "    simple_flags = np.array([0, 0, 1, 0, 1, 0, 0, 1], dtype=np.int32)  # Corrected\n",
    "    simple_values = np.array([5.0, 3.0, 2.0, 7.0, 1.0, 4.0, 6.0, 8.0], dtype=np.float32)\n",
    "    simple_seg_ids = CPUFinancialPrimitives.exclusive_scan(simple_flags)\n",
    "\n",
    "    print(f\"Computing ALL primitive operations...\")\n",
    "\n",
    "    simple_test = {\n",
    "        'name': 'simple_test_with_reduce',\n",
    "        'description': 'Basic test with ALL primitives - SCAN + REDUCE',\n",
    "        'flags': simple_flags.tolist(),\n",
    "        'values': simple_values.tolist(),\n",
    "        'reference_results': {\n",
    "            # Scan operations (cumulative)\n",
    "            'exclusive_scan': simple_seg_ids.tolist(),\n",
    "            'segmented_scan_sum': CPUFinancialPrimitives.segmented_scan_sum(simple_values, simple_seg_ids).tolist(),\n",
    "            'segmented_scan_max': CPUFinancialPrimitives.segmented_scan_max(simple_values, simple_seg_ids).tolist(),\n",
    "\n",
    "            # Reduce operations (final per segment)\n",
    "            'segmented_reduce_sum': CPUFinancialPrimitives.segmented_reduce_sum(simple_values, simple_seg_ids).tolist(),\n",
    "            'segmented_reduce_max': CPUFinancialPrimitives.segmented_reduce_max(simple_values, simple_seg_ids).tolist(),\n",
    "            'segmented_reduce_min': CPUFinancialPrimitives.segmented_reduce_min(simple_values, simple_seg_ids).tolist(),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Financial test data\n",
    "    np.random.seed(42)\n",
    "    n_days = 770\n",
    "    base_price = 100.0\n",
    "    prices = [base_price]\n",
    "\n",
    "    for i in range(1, n_days):\n",
    "        daily_return = np.random.normal(0.001, 0.02)\n",
    "        new_price = prices[-1] * (1 + daily_return)\n",
    "        prices.append(max(new_price, 1.0))\n",
    "\n",
    "    prices = np.array(prices, dtype=np.float32)\n",
    "\n",
    "    # Create segments\n",
    "    flags = np.zeros(n_days, dtype=np.int32)\n",
    "    flags[::20] = 1  # Segment every 20 days\n",
    "    flags[-1] = 1   # End last segment\n",
    "    seg_ids = CPUFinancialPrimitives.exclusive_scan(flags)\n",
    "\n",
    "    # Multi-security portfolio\n",
    "    n_securities = 3\n",
    "    prices_multi = np.tile(prices, (n_securities, 1))\n",
    "    for i in range(1, n_securities):\n",
    "        prices_multi[i] *= (0.5 + i * 0.5)\n",
    "    holdings = np.ones_like(prices_multi) * 100\n",
    "\n",
    "    # Compute ALL operations\n",
    "    print(f\"Computing all scan operations...\")\n",
    "    scan_sum = CPUFinancialPrimitives.segmented_scan_sum(prices, seg_ids)\n",
    "    scan_max = CPUFinancialPrimitives.segmented_scan_max(prices, seg_ids)\n",
    "\n",
    "    print(f\"Computing all reduce operations...\")\n",
    "    reduce_sum = CPUFinancialPrimitives.segmented_reduce_sum(prices, seg_ids)\n",
    "    reduce_max = CPUFinancialPrimitives.segmented_reduce_max(prices, seg_ids)\n",
    "    reduce_min = CPUFinancialPrimitives.segmented_reduce_min(prices, seg_ids)\n",
    "\n",
    "    print(f\"Computing all financial metrics...\")\n",
    "    cum_returns = CPUFinancialMetrics.cumulative_returns(prices, seg_ids)\n",
    "    sma_5 = CPUFinancialMetrics.simple_moving_average(prices, seg_ids, 5)\n",
    "    sma_20 = CPUFinancialMetrics.simple_moving_average(prices, seg_ids, 20)\n",
    "    rolling_std_10 = CPUFinancialMetrics.rolling_std(prices, seg_ids, 10)\n",
    "    rolling_std_20 = CPUFinancialMetrics.rolling_std(prices, seg_ids, 20)\n",
    "    max_dd = CPUFinancialMetrics.max_drawdown(prices, seg_ids)\n",
    "    portfolio_val = CPUFinancialMetrics.portfolio_value(holdings, prices_multi)\n",
    "    hwm = CPUFinancialMetrics.high_water_mark(portfolio_val, seg_ids)\n",
    "\n",
    "    financial_test = {\n",
    "        'name': 'financial_with_reduce',\n",
    "        'description': f'Financial dataset with SCAN + REDUCE operations',\n",
    "        'prices': prices.tolist(),\n",
    "        'prices_multi': prices_multi.tolist(),\n",
    "        'holdings': holdings.tolist(),\n",
    "        'flags': flags.tolist(),\n",
    "        'seg_ids': seg_ids.tolist(),\n",
    "        'n_days': n_days,\n",
    "        'n_securities': n_securities,\n",
    "        'n_segments': len(reduce_sum),  # Number of segments from reduce\n",
    "        'reference_results': {\n",
    "            # Scan operations (cumulative)\n",
    "            'segmented_scan_sum': scan_sum.tolist(),\n",
    "            'segmented_scan_max': scan_max.tolist(),\n",
    "\n",
    "            # Reduce operations (final per segment)\n",
    "            'segmented_reduce_sum': reduce_sum.tolist(),\n",
    "            'segmented_reduce_max': reduce_max.tolist(),\n",
    "            'segmented_reduce_min': reduce_min.tolist(),\n",
    "\n",
    "            # Financial metrics\n",
    "            'cumulative_returns': cum_returns.tolist(),\n",
    "            'simple_moving_average_w5': sma_5.tolist(),\n",
    "            'simple_moving_average_w20': sma_20.tolist(),\n",
    "            'rolling_std_w10': rolling_std_10.tolist(),\n",
    "            'rolling_std_w20': rolling_std_20.tolist(),\n",
    "            'max_drawdown': max_dd.tolist(),\n",
    "            'portfolio_value': portfolio_val.tolist(),\n",
    "            'high_water_mark': hwm.tolist(),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create test suite\n",
    "    test_suite = {\n",
    "        'version': '7.0.0-complete',\n",
    "        'created': datetime.now().isoformat(),\n",
    "        'description': 'GPU Test Suite - ALL primitives + financial metrics',\n",
    "        'environment': {\n",
    "            'generated_in': CURRENT_ENV,\n",
    "            'all_tests_passed': all_tests_passed,\n",
    "            'validation_status': 'COMPREHENSIVE - All functions verified'\n",
    "        },\n",
    "        'tolerance': 1e-5,\n",
    "        'primitives_summary': {\n",
    "            'total_primitives': 6,\n",
    "            'scan_operations': ['exclusive_scan', 'segmented_scan_sum', 'segmented_scan_max'],\n",
    "            'reduce_operations': ['segmented_reduce_sum', 'segmented_reduce_max', 'segmented_reduce_min']\n",
    "        },\n",
    "        'validation_summary': {\n",
    "            'total_functions': 12,\n",
    "            'primitive_functions': 6,  # 3 scan + 3 reduce\n",
    "            'financial_functions': 6,\n",
    "            'test_coverage': 'COMPLETE',\n",
    "            'numerical_accuracy': 'VERIFIED',\n",
    "            'edge_cases': 'TESTED',\n",
    "            'scan_reduce_consistency': 'VERIFIED'\n",
    "        },\n",
    "        'student_targets': {\n",
    "            'functions_to_implement': 12,\n",
    "            'minimum_speedup': '5x faster than CPU',\n",
    "            'excellent_speedup': '10x faster than CPU'\n",
    "        },\n",
    "        'tests': {\n",
    "            'simple': simple_test,\n",
    "            'financial': financial_test\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save with comprehensive naming\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    main_filename = f\"cpu_test_fixtures_{timestamp}.json\"\n",
    "\n",
    "    saved_path = save_fixtures_universal(test_suite, main_filename)\n",
    "    generic_path = save_fixtures_universal(test_suite, \"cpu_test_fixtures.json\")\n",
    "\n",
    "    print(f\"\\nTEST FIXTURES GENERATED!\")\n",
    "    print(f\"=\" * 60)\n",
    "    print(f\"Timestamped: {main_filename}\")\n",
    "    print(f\"Generic: gpu_test_fixtures.json\")\n",
    "    print(f\"\\nVALIDATION SUMMARY:\")\n",
    "    print(f\"   Scan primitives (3/3): exclusive_scan, segmented_scan_sum, segmented_scan_max\")\n",
    "    print(f\"   Reduce primitives (3/3): segmented_reduce_sum, segmented_reduce_max, segmented_reduce_min\")\n",
    "    print(f\"   Financial metrics (6/6): ALL VALIDATED\")\n",
    "    print(f\"   Total functions: 12/12\")\n",
    "    print(f\"   Consistency checks: scan vs reduce verified\")\n",
    "\n",
    "    return test_suite\n",
    "\n",
    "# Generate complete test fixtures\n",
    "complete_test_suite = generate_complete_fixtures()\n",
    "\n",
    "if complete_test_suite:\n",
    "    print(f\"\\nSUCCESS! Complete test fixture!\")\n",
    "    print(f\"Students now have the full primitive toolkit for GPU implementation!\")\n",
    "else:\n",
    "    print(f\"\\nFix any test failures before generating complete fixtures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOOP1UY_zSv0"
   },
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103116,
     "status": "ok",
     "timestamp": 1760700639533,
     "user": {
      "displayName": "Lilian Aveneau",
      "userId": "13487831906381711345"
     },
     "user_tz": -420
    },
    "id": "XGIKVR9CzSv0",
    "outputId": "bfd96e76-c72b-468d-c8f9-7e13c327235c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CPU PERFORMANCE BENCHMARK\n",
      "======================================================================\n",
      "\n",
      "Benchmarking 12 functions with 5 runs each...\n",
      "Data size: 1,000,000 elements\n",
      "\n",
      "exclusive_scan                  263.254 ±  8.381 ms  (  3.80 M/s)\n",
      "segmented_scan_sum              234.870 ± 10.490 ms  (  4.26 M/s)\n",
      "segmented_scan_max              296.029 ±  2.284 ms  (  3.38 M/s)\n",
      "segmented_reduce_sum            279.620 ±  5.525 ms  (  3.58 M/s)\n",
      "segmented_reduce_max            337.428 ±  8.427 ms  (  2.96 M/s)\n",
      "segmented_reduce_min            334.728 ±  2.710 ms  (  2.99 M/s)\n",
      "cumulative_returns              793.172 ± 10.635 ms  (  1.26 M/s)\n",
      "simple_moving_average          1765.685 ± 24.234 ms  (  0.57 M/s)\n",
      "rolling_std                      56.679 ±  0.652 ms  ( 17.64 M/s)\n",
      "max_drawdown                    305.851 ± 10.329 ms  (  3.27 M/s)\n",
      "portfolio_value                   0.023 ±  0.006 ms  (44272.48 M/s)\n",
      "high_water_mark                   3.159 ±  0.091 ms  (316.60 M/s)\n",
      "\n",
      "======================================================================\n",
      "BENCHMARK SUMMARY\n",
      "======================================================================\n",
      "Functions benchmarked: 12/12\n",
      "Total CPU time: 4670.496 ms\n",
      "Average throughput: 3719.40 M elements/sec\n",
      "\n",
      "These timings will be used as GPU baseline comparisons\n",
      "SAVING FIXTURES cpu_benchmarks_1M.json\n",
      "============================================================\n",
      "Saved locally: /home/quydx/advancedhpc2025/project/cpu_benchmarks_1M.json\n",
      "CPU benchmark results saved to cpu_benchmarks_1M.json\n"
     ]
    }
   ],
   "source": [
    "## Performance Benchmarking\n",
    "\n",
    "class CPUBenchmark:\n",
    "    \"\"\"Clean benchmark framework for CPU functions.\"\"\"\n",
    "\n",
    "    def __init__(self, n_elements=50000):\n",
    "        self.n_elements = n_elements\n",
    "        self.n_runs = 5\n",
    "        self.results = {}\n",
    "        self.burnin_iterations = 4\n",
    "\n",
    "    def generate_test_data(self):\n",
    "        \"\"\"Generate test data for benchmarking.\"\"\"\n",
    "        np.random.seed(42)\n",
    "\n",
    "        # Generate segment flags and IDs\n",
    "        flags = np.zeros(self.n_elements, dtype=np.int32)\n",
    "        flags[::100] = 1  # Segment every 100 elements\n",
    "        flags[-1] = 1\n",
    "        seg_ids = CPUFinancialPrimitives.exclusive_scan(flags)\n",
    "\n",
    "        # Generate values and prices\n",
    "        values = np.random.randn(self.n_elements).astype(np.float32)\n",
    "        prices = np.abs(values) + 100\n",
    "\n",
    "        # Generate multi-security portfolio data\n",
    "        n_securities = 3\n",
    "        n_days = min(self.n_elements, 10000)\n",
    "        prices_multi = np.tile(prices[:n_days], (n_securities, 1))\n",
    "        holdings = np.ones_like(prices_multi) * 100\n",
    "\n",
    "        return {\n",
    "            'flags': flags,\n",
    "            'seg_ids': seg_ids,\n",
    "            'values': values,\n",
    "            'prices': prices,\n",
    "            'holdings': holdings,\n",
    "            'prices_multi': prices_multi,\n",
    "            'n_days': n_days\n",
    "        }\n",
    "\n",
    "    def get_functions_to_benchmark(self, data):\n",
    "        \"\"\"Define all functions to benchmark.\"\"\"\n",
    "        return [\n",
    "            # Primitives\n",
    "            ('exclusive_scan',\n",
    "             lambda: CPUFinancialPrimitives.exclusive_scan(data['flags'])),\n",
    "            ('segmented_scan_sum',\n",
    "             lambda: CPUFinancialPrimitives.segmented_scan_sum(data['values'], data['seg_ids'])),\n",
    "            ('segmented_scan_max',\n",
    "             lambda: CPUFinancialPrimitives.segmented_scan_max(data['values'], data['seg_ids'])),\n",
    "            ('segmented_reduce_sum',\n",
    "             lambda: CPUFinancialPrimitives.segmented_reduce_sum(data['values'], data['seg_ids'])),\n",
    "            ('segmented_reduce_max',\n",
    "             lambda: CPUFinancialPrimitives.segmented_reduce_max(data['values'], data['seg_ids'])),\n",
    "            ('segmented_reduce_min',\n",
    "             lambda: CPUFinancialPrimitives.segmented_reduce_min(data['values'], data['seg_ids'])),\n",
    "\n",
    "            # Financial metrics\n",
    "            ('cumulative_returns',\n",
    "             lambda: CPUFinancialMetrics.cumulative_returns(data['prices'], data['seg_ids'])),\n",
    "            ('simple_moving_average',\n",
    "             lambda: CPUFinancialMetrics.simple_moving_average(data['prices'], data['seg_ids'], 5)),\n",
    "            ('rolling_std',\n",
    "             lambda: CPUFinancialMetrics.rolling_std(data['prices'][:10000], data['seg_ids'][:10000], 10)),\n",
    "            ('max_drawdown',\n",
    "             lambda: CPUFinancialMetrics.max_drawdown(data['prices'], data['seg_ids'])),\n",
    "            ('portfolio_value',\n",
    "             lambda: CPUFinancialMetrics.portfolio_value(data['holdings'], data['prices_multi'])),\n",
    "            ('high_water_mark',\n",
    "             lambda: CPUFinancialMetrics.high_water_mark(\n",
    "                 CPUFinancialMetrics.portfolio_value(data['holdings'], data['prices_multi']),\n",
    "                 data['seg_ids'][:data['n_days']]))\n",
    "        ]\n",
    "\n",
    "    def benchmark_function(self, func_name, func_call):\n",
    "        \"\"\"Benchmark a single function.\"\"\"\n",
    "        try:\n",
    "            # Warmup\n",
    "            for i in range(self.burnin_iterations):\n",
    "                _ = func_call()\n",
    "\n",
    "            # Benchmark runs\n",
    "            times = []\n",
    "            for _ in range(self.n_runs):\n",
    "                start = time.perf_counter()\n",
    "                _ = func_call()\n",
    "                end = time.perf_counter()\n",
    "                times.append(end - start)\n",
    "\n",
    "            # Calculate statistics\n",
    "            avg_time_ms = np.mean(times) * 1000\n",
    "            std_time_ms = np.std(times) * 1000\n",
    "            throughput = self.n_elements / np.mean(times) / 1e6\n",
    "\n",
    "            return {\n",
    "                'status': 'success',\n",
    "                'avg_time_ms': avg_time_ms,\n",
    "                'std_time_ms': std_time_ms,\n",
    "                'throughput_M_per_sec': throughput\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {'status': 'error', 'message': str(e)}\n",
    "\n",
    "    def print_function_result(self, func_name, result):\n",
    "        \"\"\"Print benchmark result for a single function.\"\"\"\n",
    "        if result['status'] == 'success':\n",
    "            print(f\"{func_name:30s} {result['avg_time_ms']:8.3f} ± {result['std_time_ms']:6.3f} ms\"\n",
    "                  f\"  ({result['throughput_M_per_sec']:6.2f} M/s)\")\n",
    "        else:\n",
    "            print(f\"{func_name:30s} Error: {result.get('message', 'Unknown error')}\")\n",
    "\n",
    "    def calculate_summary(self):\n",
    "        \"\"\"Calculate overall benchmark summary.\"\"\"\n",
    "        successful = {k: v for k, v in self.results.items()\n",
    "                     if v.get('status') == 'success'}\n",
    "\n",
    "        if not successful:\n",
    "            return {'successful': 0, 'total': len(self.results)}\n",
    "\n",
    "        total_time = sum(v['avg_time_ms'] for v in successful.values())\n",
    "        avg_throughput = np.mean([v['throughput_M_per_sec'] for v in successful.values()])\n",
    "\n",
    "        return {\n",
    "            'successful': len(successful),\n",
    "            'total': len(self.results),\n",
    "            'total_time_ms': total_time,\n",
    "            'avg_throughput': avg_throughput\n",
    "        }\n",
    "\n",
    "    def print_summary(self, summary):\n",
    "        \"\"\"Print benchmark summary.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"BENCHMARK SUMMARY\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        if summary['successful'] == 0:\n",
    "            print(\"No successful benchmarks\")\n",
    "            return\n",
    "\n",
    "        print(f\"Functions benchmarked: {summary['successful']}/{summary['total']}\")\n",
    "        print(f\"Total CPU time: {summary['total_time_ms']:.3f} ms\")\n",
    "        print(f\"Average throughput: {summary['avg_throughput']:.2f} M elements/sec\")\n",
    "        print(f\"\\nThese timings will be used as GPU baseline comparisons\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run complete benchmark suite.\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"CPU PERFORMANCE BENCHMARK\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        # Generate test data\n",
    "        data = self.generate_test_data()\n",
    "        functions = self.get_functions_to_benchmark(data)\n",
    "\n",
    "        print(f\"\\nBenchmarking {len(functions)} functions with {self.n_runs} runs each...\")\n",
    "        print(f\"Data size: {self.n_elements:,} elements\\n\")\n",
    "\n",
    "        # Benchmark each function\n",
    "        for func_name, func_call in functions:\n",
    "            result = self.benchmark_function(func_name, func_call)\n",
    "            self.results[func_name] = result\n",
    "            self.print_function_result(func_name, result)\n",
    "\n",
    "        # Print summary\n",
    "        summary = self.calculate_summary()\n",
    "        self.print_summary(summary)\n",
    "\n",
    "        return self.results\n",
    "\n",
    "\n",
    "# Run CPU benchmark\n",
    "cpu_benchmark = CPUBenchmark(n_elements=1000000)\n",
    "cpu_benchmark_results = cpu_benchmark.run()\n",
    "\n",
    "# Export CPU benchmark results for GPU comparison\n",
    "benchmark_export = {\n",
    "    'n_elements': 1000000,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'cpu_benchmarks': {\n",
    "        name: {\n",
    "            'avg_time_ms': result['avg_time_ms'],\n",
    "            'std_time_ms': result['std_time_ms'],\n",
    "            'throughput_M_per_sec': result['throughput_M_per_sec']\n",
    "        }\n",
    "        for name, result in cpu_benchmark_results.items()\n",
    "        if result.get('status') == 'success'\n",
    "    }\n",
    "}\n",
    "\n",
    "save_fixtures_universal(benchmark_export, 'cpu_benchmarks_1M.json')\n",
    "\n",
    "print(\"CPU benchmark results saved to cpu_benchmarks_1M.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ7VQRmHzSv1"
   },
   "source": [
    "## That's all, folks!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
